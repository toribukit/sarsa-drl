[2022-05-24 12:44:45,686 PID:59919 INFO openai.py __init__] OpenAIEnv:
- env_spec = {'max_frame': 100000, 'max_t': None, 'name': 'CartPole-v0'}
- eval_frequency = 2000
- log_frequency = 10000
- frame_op = None
- frame_op_len = None
- image_downsize = (84, 84)
- normalize_state = False
- reward_scale = None
- num_envs = 1
- name = CartPole-v0
- max_t = 200
- max_frame = 100000
- to_render = False
- is_venv = False
- clock_speed = 1
- clock = <slm_lab.env.base.Clock object at 0x7f9bf59cb080>
- done = False
- total_reward = nan
- u_env = <TrackReward<TimeLimit<CartPoleEnv<CartPole-v0>>>>
- observation_space = Box(4,)
- action_space = Discrete(2)
- observable_dim = {'state': 4}
- action_dim = 2
- is_discrete = True
[2022-05-24 12:44:45,690 PID:59919 INFO base.py end_init_nets] Initialized algorithm models for lab_mode: train
[2022-05-24 12:44:45,693 PID:59919 INFO base.py __init__] SARSA:
- agent = <slm_lab.agent.Agent object at 0x7f9b6c897ba8>
- action_pdtype = Argmax
- action_policy = <function epsilon_greedy at 0x7f9bb093ef28>
- explore_var_spec = {'end_step': 10000,
 'end_val': 0.05,
 'name': 'linear_decay',
 'start_step': 0,
 'start_val': 1.0}
- gamma = 0.99
- training_frequency = 5
- to_train = 0
- explore_var_scheduler = <slm_lab.agent.algorithm.policy_util.VarScheduler object at 0x7f9b36f084a8>
- net = MLPNet(
  (model): Sequential(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): SELU()
  )
  (model_tail): Sequential(
    (0): Linear(in_features=64, out_features=2, bias=True)
  )
  (loss_fn): MSELoss()
)
- net_names = ['net']
- optim = RMSprop (
Parameter Group 0
    alpha: 0.99
    centered: False
    eps: 1e-08
    lr: 0.01
    momentum: 0
    weight_decay: 0
)
- lr_scheduler = <slm_lab.agent.net.net_util.NoOpLRScheduler object at 0x7f9b36f08860>
- global_net = None
[2022-05-24 12:44:45,694 PID:59919 INFO __init__.py __init__] Agent:
- spec = {'cuda_offset': 0,
 'distributed': False,
 'eval_frequency': 2000,
 'experiment': 0,
 'experiment_ts': '2022_05_24_124444',
 'git_sha': '9102ff923d7a3e9c579edc18c6547cce94a7b77a',
 'graph_prepath': 'data/sarsa_epsilon_greedy_cartpole_2022_05_24_124444/graph/sarsa_epsilon_greedy_cartpole_t0_s1',
 'info_prepath': 'data/sarsa_epsilon_greedy_cartpole_2022_05_24_124444/info/sarsa_epsilon_greedy_cartpole_t0_s1',
 'log_prepath': 'data/sarsa_epsilon_greedy_cartpole_2022_05_24_124444/log/sarsa_epsilon_greedy_cartpole_t0_s1',
 'max_session': 4,
 'max_trial': 1,
 'model_prepath': 'data/sarsa_epsilon_greedy_cartpole_2022_05_24_124444/model/sarsa_epsilon_greedy_cartpole_t0_s1',
 'prepath': 'data/sarsa_epsilon_greedy_cartpole_2022_05_24_124444/sarsa_epsilon_greedy_cartpole_t0_s1',
 'random_seed': 1653364885,
 'resume': False,
 'rigorous_eval': 0,
 'session': 1,
 'trial': 0}
- agent_spec = {'algorithm': {'action_pdtype': 'Argmax',
               'action_policy': 'epsilon_greedy',
               'explore_var_spec': {'end_step': 10000,
                                    'end_val': 0.05,
                                    'name': 'linear_decay',
                                    'start_step': 0,
                                    'start_val': 1.0},
               'gamma': 0.99,
               'name': 'SARSA',
               'training_frequency': 5},
 'memory': {'name': 'OnPolicyBatchReplay'},
 'name': 'SARSA',
 'net': {'clip_grad_val': 0.5,
         'hid_layers': [64],
         'hid_layers_activation': 'selu',
         'loss_spec': {'name': 'MSELoss'},
         'lr_scheduler_spec': None,
         'optim_spec': {'lr': 0.01, 'name': 'RMSprop'},
         'type': 'MLPNet'}}
- name = SARSA
- body = body: {
  "agent": "<slm_lab.agent.Agent object at 0x7f9b6c897ba8>",
  "env": "<slm_lab.env.openai.OpenAIEnv object at 0x7f9bf59b6e80>",
  "a": 0,
  "e": 0,
  "b": 0,
  "aeb": "(0, 0, 0)",
  "explore_var": 1.0,
  "entropy_coef": NaN,
  "loss": NaN,
  "mean_entropy": NaN,
  "mean_grad_norm": NaN,
  "best_total_reward_ma": -Infinity,
  "total_reward_ma": NaN,
  "train_df": "Empty DataFrame\nColumns: [epi, t, wall_t, opt_step, frame, fps, total_reward, total_reward_ma, loss, lr, explore_var, entropy_coef, entropy, grad_norm]\nIndex: []",
  "eval_df": "Empty DataFrame\nColumns: [epi, t, wall_t, opt_step, frame, fps, total_reward, total_reward_ma, loss, lr, explore_var, entropy_coef, entropy, grad_norm]\nIndex: []",
  "observation_space": "Box(4,)",
  "action_space": "Discrete(2)",
  "observable_dim": {
    "state": 4
  },
  "state_dim": 4,
  "action_dim": 2,
  "is_discrete": true,
  "action_type": "discrete",
  "action_pdtype": "Argmax",
  "ActionPD": "<class 'slm_lab.lib.distribution.Argmax'>",
  "memory": "<slm_lab.agent.memory.onpolicy.OnPolicyBatchReplay object at 0x7f9b36ef4400>"
}
- algorithm = <slm_lab.agent.algorithm.sarsa.SARSA object at 0x7f9b36f08940>
[2022-05-24 12:44:45,695 PID:59919 INFO logger.py info] Session:
- spec = {'cuda_offset': 0,
 'distributed': False,
 'eval_frequency': 2000,
 'experiment': 0,
 'experiment_ts': '2022_05_24_124444',
 'git_sha': '9102ff923d7a3e9c579edc18c6547cce94a7b77a',
 'graph_prepath': 'data/sarsa_epsilon_greedy_cartpole_2022_05_24_124444/graph/sarsa_epsilon_greedy_cartpole_t0_s1',
 'info_prepath': 'data/sarsa_epsilon_greedy_cartpole_2022_05_24_124444/info/sarsa_epsilon_greedy_cartpole_t0_s1',
 'log_prepath': 'data/sarsa_epsilon_greedy_cartpole_2022_05_24_124444/log/sarsa_epsilon_greedy_cartpole_t0_s1',
 'max_session': 4,
 'max_trial': 1,
 'model_prepath': 'data/sarsa_epsilon_greedy_cartpole_2022_05_24_124444/model/sarsa_epsilon_greedy_cartpole_t0_s1',
 'prepath': 'data/sarsa_epsilon_greedy_cartpole_2022_05_24_124444/sarsa_epsilon_greedy_cartpole_t0_s1',
 'random_seed': 1653364885,
 'resume': False,
 'rigorous_eval': 0,
 'session': 1,
 'trial': 0}
- index = 1
- agent = <slm_lab.agent.Agent object at 0x7f9b6c897ba8>
- env = <slm_lab.env.openai.OpenAIEnv object at 0x7f9bf59b6e80>
- eval_env = <slm_lab.env.openai.OpenAIEnv object at 0x7f9bf59b6e80>
[2022-05-24 12:44:45,695 PID:59919 INFO logger.py info] Running RL loop for trial 0 session 1
[2022-05-24 12:44:45,698 PID:59919 INFO __init__.py log_summary] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df] epi: 0  t: 0  wall_t: 0  opt_step: 0  frame: 0  fps: 0  total_reward: nan  total_reward_ma: nan  loss: nan  lr: 0.01  explore_var: 1  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-05-24 12:47:48,266 PID:59919 INFO __init__.py log_summary] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df] epi: 354  t: 2  wall_t: 182  opt_step: 12000  frame: 10000  fps: 54.9451  total_reward: 59  total_reward_ma: 59  loss: 14085  lr: 0.01  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-05-24 12:52:52,241 PID:59919 INFO __init__.py log_summary] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df] epi: 614  t: 180  wall_t: 486  opt_step: 24000  frame: 20000  fps: 41.1523  total_reward: 200  total_reward_ma: 129.5  loss: 0.203824  lr: 0.01  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-05-24 12:52:52,262 PID:59919 INFO __init__.py log_metrics] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df metrics] final_return_ma: 129.5  strength: 107.64  max_strength: 178.14  final_strength: 178.14  sample_efficiency: 5.8626e-05  training_efficiency: 4.8855e-05  stability: 1
[2022-05-24 12:58:17,410 PID:59919 INFO __init__.py log_summary] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df] epi: 671  t: 142  wall_t: 811  opt_step: 36000  frame: 30000  fps: 36.9914  total_reward: 200  total_reward_ma: 153  loss: 0.0410428  lr: 0.01  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-05-24 12:58:17,419 PID:59919 INFO __init__.py log_metrics] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df metrics] final_return_ma: 153  strength: 131.14  max_strength: 178.14  final_strength: 178.14  sample_efficiency: 4.71735e-05  training_efficiency: 3.93113e-05  stability: 1
[2022-05-24 13:04:01,017 PID:59919 INFO __init__.py log_summary] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df] epi: 733  t: 9  wall_t: 1155  opt_step: 48000  frame: 40000  fps: 34.632  total_reward: 200  total_reward_ma: 164.75  loss: 0.0152466  lr: 0.01  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-05-24 13:04:01,026 PID:59919 INFO __init__.py log_metrics] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df metrics] final_return_ma: 164.75  strength: 142.89  max_strength: 178.14  final_strength: 178.14  sample_efficiency: 4.02626e-05  training_efficiency: 3.35522e-05  stability: 1
[2022-05-24 13:08:52,498 PID:59919 INFO __init__.py log_summary] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df] epi: 784  t: 10  wall_t: 1446  opt_step: 60000  frame: 50000  fps: 34.5781  total_reward: 200  total_reward_ma: 171.8  loss: 0.695267  lr: 0.01  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-05-24 13:08:52,507 PID:59919 INFO __init__.py log_metrics] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df metrics] final_return_ma: 171.8  strength: 149.94  max_strength: 178.14  final_strength: 178.14  sample_efficiency: 3.54479e-05  training_efficiency: 2.95399e-05  stability: 1
[2022-05-24 13:14:46,173 PID:59919 INFO __init__.py log_summary] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df] epi: 840  t: 157  wall_t: 1800  opt_step: 72000  frame: 60000  fps: 33.3333  total_reward: 200  total_reward_ma: 176.5  loss: 0.0530438  lr: 0.01  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-05-24 13:14:46,182 PID:59919 INFO __init__.py log_metrics] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df metrics] final_return_ma: 176.5  strength: 154.64  max_strength: 178.14  final_strength: 178.14  sample_efficiency: 3.1842e-05  training_efficiency: 2.6535e-05  stability: 1
[2022-05-24 13:19:57,098 PID:59919 INFO __init__.py log_summary] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df] epi: 893  t: 32  wall_t: 2111  opt_step: 84000  frame: 70000  fps: 33.1596  total_reward: 200  total_reward_ma: 179.857  loss: 0.0434532  lr: 0.01  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-05-24 13:19:57,118 PID:59919 INFO __init__.py log_metrics] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df metrics] final_return_ma: 179.857  strength: 157.997  max_strength: 178.14  final_strength: 178.14  sample_efficiency: 2.90142e-05  training_efficiency: 2.41785e-05  stability: 1
[2022-05-24 13:25:18,138 PID:59919 INFO __init__.py log_summary] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df] epi: 946  t: 200  wall_t: 2432  opt_step: 96000  frame: 80000  fps: 32.8947  total_reward: 200  total_reward_ma: 182.375  loss: 1028.64  lr: 0.01  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-05-24 13:25:18,156 PID:59919 INFO __init__.py log_metrics] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df metrics] final_return_ma: 182.375  strength: 160.515  max_strength: 178.14  final_strength: 178.14  sample_efficiency: 2.67233e-05  training_efficiency: 2.22694e-05  stability: 1
[2022-05-24 13:25:18,158 PID:59919 INFO __init__.py log_summary] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df] epi: 946  t: 200  wall_t: 2432  opt_step: 96000  frame: 80000  fps: 32.8947  total_reward: 200  total_reward_ma: 182.375  loss: 1028.64  lr: 0.01  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-05-24 13:25:18,168 PID:59919 INFO __init__.py log_metrics] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df metrics] final_return_ma: 182.375  strength: 160.515  max_strength: 178.14  final_strength: 178.14  sample_efficiency: 2.67233e-05  training_efficiency: 2.22694e-05  stability: 1
[2022-05-24 13:30:00,408 PID:59919 INFO __init__.py log_summary] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df] epi: 1003  t: 65  wall_t: 2714  opt_step: 108000  frame: 90000  fps: 33.1614  total_reward: 200  total_reward_ma: 184.333  loss: 0.27437  lr: 0.01  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-05-24 13:30:00,428 PID:59919 INFO __init__.py log_metrics] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df metrics] final_return_ma: 184.333  strength: 162.473  max_strength: 178.14  final_strength: 178.14  sample_efficiency: 2.48213e-05  training_efficiency: 2.06844e-05  stability: 1
[2022-05-24 13:33:02,203 PID:59919 INFO __init__.py log_summary] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df] epi: 1060  t: 43  wall_t: 2896  opt_step: 120000  frame: 100000  fps: 34.5304  total_reward: 200  total_reward_ma: 185.9  loss: 0.0672091  lr: 0.01  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-05-24 13:33:02,213 PID:59919 INFO __init__.py log_metrics] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [train_df metrics] final_return_ma: 185.9  strength: 164.04  max_strength: 178.14  final_strength: 178.14  sample_efficiency: 2.32118e-05  training_efficiency: 1.93432e-05  stability: 1
[2022-05-24 13:33:03,295 PID:59919 INFO __init__.py log_metrics] Trial 0 session 1 sarsa_epsilon_greedy_cartpole_t0_s1 [eval_df metrics] final_return_ma: 185.9  strength: 164.04  max_strength: 178.14  final_strength: 178.14  sample_efficiency: 2.32118e-05  training_efficiency: 1.93432e-05  stability: 1
[2022-05-24 13:33:03,296 PID:59919 INFO logger.py info] Session 1 done
